{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (k-Nearest Neighbors) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 데이터의 카테고리 분류를 할때 사용한다.\n",
    "\n",
    "2D 그래프에 점이 막 찍혀있고 각 점의 카테고리가 이미 분류 되어있다고 가정하자.\n",
    "이 상태에서 분류해야하는 새로운 점이 하나 찍혔다!\n",
    "이때 이 새로운점은 어떤 카테고리로 분류해야할까??\n",
    "\n",
    "### K 가 뭔가?\n",
    "- 최근접점을 몇개까지 볼거냐\n",
    "- 기본적으로 홀수를 쓴다.\n",
    "- 작은 수를 쓴다.\n",
    "\n",
    "### 최근접점을 그래프에서 어떻게 구할것이냐?\n",
    "- 피타고라스 정리를 이용한다.\n",
    "- $distance^2 = a^2 + b^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사결정 트리 (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 접근 과정\n",
    "1. 우리가 해결하고자 하는 문제의 설정\n",
    "2. 머신러닝에 활용할 학습 data 수집\n",
    "3. 학습데이터의 분류 (수작업)\n",
    "  - 건별 데이터마다 속성값이 있음\n",
    "4. Tree 구조의 의사결정 로직을 만들어준다. \n",
    "  - 어떤속성부터 분류 작업을 적용할 것인가\n",
    "  - 어떤 속성부터 split 해야 가장 효율적으로 분류할수 있을지 고민이 필요\n",
    "  - 초반부에 많이 걸러낼수록 좋다.\n",
    "5. 머신 배포 후 활용\n",
    "\n",
    "### 엔트로피(entropy)\n",
    "- 높은경우: 어질러진 상태\n",
    "- 낮은경우: 깔끔한 상태\n",
    "\n",
    "### 정보 습득량(= Information Gain)\n",
    "- base entropy - new entropy\n",
    "- 엔트로피 감소량을 뜻하는것으로 얻어지는 정보량의 측정 값을 의미\n",
    "- 의사결정 Tree 에 의해 많이 걸러질수록 그만큼 entropy 가 낮아지며,\n",
    "- 많이 필터링되는 Tree Node 가 Information Gain 수치가 높다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개요\n",
    "- 의사결정 Tree 에서 하나의 속성을 잡고 데이터를 나눌때 가장 많이 쓰이는 알고리즘\n",
    "- 위에서 설명한 entropy 와 information gain 2가지 컨셉을 가지고 있음.\n",
    "- 특정 속성에 의해 데이터 정답셋을 분류하는 엔트로피를 계산하는 공식이있음.\n",
    "- 주어진 상황 엔트로피 구하는법: 전체 데이터 set 에서 우리가 의사결정 트리에 의해 최종적으로 얻고자 하는 정답 set 의 엔트로피 = 총 8개중에 1개라면 =  Entropy([1+, 7-])\n",
    "- 속성별 Information Gain 구하는법: 주어진 상황 엔트로피 - 하나의 속성을 잡았을때 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bays Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작하기전에 - 확률 이론\n",
    "$P(A) = \\frac{(A가 발생하는 경우의 수)}{(전체 경우의 수)}$\n",
    "\n",
    "### 시작하기전에 - Conditional Probability\n",
    "-  조건부 확률 = 주어진 상황에서 다른 상황이 일어날 확률\n",
    "- 서로 영향을 끼치지 않는 경우가 있고\n",
    "- 서로 영향을 끼치는 경우가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이건 잘 이해가 안갔음.\n",
    "\n",
    "다른 자료를 찾아볼것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 (Classification) 와 회귀 (Regression)\n",
    "\n",
    "- 분류 : input -> classifier (Traing) -> A, B, C 로 구분해줌\n",
    "- 회귀 : 실바의 A 데이터를 넣었을때 실바의 B 데이터를 예측해라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "- 1차 함수 선을 그리고 그 선을 기준으로 분류하는 것.\n",
    "- 2차원 평면에 1차 그래프(직선)를 그었을때, 실제 데이터들과의 거리(에러)가 적은 모델이 더 좋은 모델이다\n",
    "- 에러를 제곱(정사각형 = square)으로 많이 표시한다.\n",
    "- 관찰된 데이터가 있을때 최적의 \n",
    "\n",
    "### least mean square error 찾기\n",
    "- Error : 함수의 해와 실제값의 오차값 = $f(x) - y$\n",
    "- Square Error: Error 의 제곱값(사각형 영역) = $(f(x) - y)^2$\n",
    "- Mean square error(cost function) : 모든 오차 사각형 넓이의 평균 = $1/N *\\sum_{i=1}^N (f(x) - y)^2 $\n",
    "- Gradient decent algo 의 세타값이 0으로 converge 되었을때, 생성되는 라인이 바로 Linear Regression Line 이다.\n",
    "\n",
    "### Gradiend Decent Algorithm\n",
    "- Gradient Decent Algorithm : 기울기가 0으로 수렴할때까지 반복한다.\n",
    "- Cost Function : 비용함수, 실제값과 가설간의 차이, 요것을 최저로 만드는것이 목표\n",
    "- Objective Function : 목표 함수. 우리가 얻고자 하는 가장 이상적인 해를 리턴헤주는 최종 함수\n",
    "- Learning rate: 최적의 $\\theta$ 를 찾기위해서 점차 최적값으로 으로 이동하는 크기를 정한다 (너무커도, 너무작아도 안됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
